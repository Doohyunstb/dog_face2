{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwZ073RKd+d1SouDDgI828",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doohyunstb/dog_face2/blob/main/find_dog_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import imutils\n",
        "from imutils import face_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import face_recognition"
      ],
      "metadata": {
        "id": "8Pvg8plF-ocZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "eyadZg7aDYvN",
        "outputId": "62427186-a3ad-4a7d-e6e5-e6e00f02a49e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-558948db5a91>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_landmark_detector_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_landmark_predictor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to open /content/drive/MyDrive/Github/dof_face2/landmarkDetector.dat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_landmark_detector_path = '/content/drive/MyDrive/Github/dog_face2/dogHeadDetector.dat'\n",
        "face_landmark_predictor_path = '/content/drive/MyDrive/Github/dog_face2/landmarkDetector.dat'"
      ],
      "metadata": {
        "id": "dILkaeP6Dx3l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = dlib.cnn_face_detection_model_v1(face_landmark_detector_path)\n",
        "predictor = dlib.shape_predictor(face_landmark_predictor_path)"
      ],
      "metadata": {
        "id": "jor-xJPOEGmv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_imshow(title='image', img=None, figsize=(8 ,5)):\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    if type(img) == list:\n",
        "        if type(title) == list:\n",
        "            titles = title\n",
        "        else:\n",
        "            titles = []\n",
        "\n",
        "            for i in range(len(img)):\n",
        "                titles.append(title)\n",
        "\n",
        "        for i in range(len(img)):\n",
        "            if len(img[i].shape) <= 2:\n",
        "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_GRAY2RGB)\n",
        "            else:\n",
        "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            plt.subplot(1, len(img), i + 1), plt.imshow(rgbImg)\n",
        "            plt.title(titles[i])\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        if len(img.shape) < 3:\n",
        "            rgbImg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.imshow(rgbImg)\n",
        "        plt.title(title)\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "o48gR1JZEVOG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _trim_css_to_bounds(css, image_shape):\n",
        "    return max(css[0], 0), min(css[1], image_shape[1]), min(css[2], image_shape[0]), max(css[3], 0)\n",
        "\n",
        "\n",
        "def _rect_to_css(rect):\n",
        "    return rect.top(), rect.right(), rect.bottom(), rect.left()\n",
        "\n",
        "\n",
        "def _raw_face_locations(img, number_of_times_to_upsample=1):\n",
        "    return detector(img, number_of_times_to_upsample)\n",
        "\n",
        "\n",
        "def face_locations(img, number_of_times_to_upsample=1):\n",
        "    return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample)]"
      ],
      "metadata": {
        "id": "uXWU6idGEXRA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_dog_face(input_image, size=None, debug=False):\n",
        "    image = input_image.copy()\n",
        "\n",
        "    if size:\n",
        "        image = imutils.resize(image, width=size)\n",
        "\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    dets = detector(gray_image, 1)\n",
        "\n",
        "    print('Found {} faces.'.format(len(dets)))\n",
        "\n",
        "    for (i, det) in enumerate(dets):\n",
        "        # 얼굴 영역의 얼굴 랜드마크를 결정한 다음\n",
        "        # 얼굴 랜드마크(x, y) 좌표를 NumPy Array로 변환합니다.\n",
        "        shape = predictor(image, det.rect)\n",
        "        shape = face_utils.shape_to_np(shape)\n",
        "\n",
        "        # dlib의 사각형을 OpenCV bounding box로 변환(x, y, w, h)\n",
        "        (x, y, w, h) = face_utils.rect_to_bb(det.rect)\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        if debug:\n",
        "            # 얼굴 랜드마크에 포인트를 그립니다.\n",
        "            for (i, (x, y)) in enumerate(shape):\n",
        "                cv2.circle(image, (x, y), int(image.shape[1]/250), (0, 0, 255), -1)\n",
        "                # cv2.putText(image, str(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.2, (255, 255, 255), 1)\n",
        "\n",
        "    plt_imshow([\"Original\", \"Find Faces\"], [input_image, image], figsize=(16,10))"
      ],
      "metadata": {
        "id": "UlwXVfXBEaER"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}